{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key starts with: sk-proj-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"Loaded API Key starts with: {OPENAI_API_KEY[:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The 2022 FIFA World Cup has not yet taken place. It is scheduled to be held in Qatar from November 21 to December 18, 2022.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 17, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnXOODZ3xK61FD1DoB5R5pwCcRZuu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7714270f-b3b9-40de-8a48-7311bfdea923-0', usage_metadata={'input_tokens': 17, 'output_tokens': 34, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Who won the world cup in 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Los Angeles Dodgers won the World Series during the COVID-19 pandemic, defeating the Tampa Bay Rays in six games in the 2020 World Series.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "doc = fitz.open(\"Lionel-June25.pdf\") \n",
    "text = \"\"\n",
    "\n",
    "for i, page in enumerate(doc):\n",
    "    text += page.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESTIMATE\\nHammer Time Home\\nImprovement HIC#0668980\\n281 Middle Tpke E\\nManchester, CT 06040\\n860hammertime@gmail.com\\n+1 (860) 830-7982\\nfacebook.com/860hammertime\\nBill to\\nSatish Kulkarni\\n1006 Sandstone Drive\\nSouth Windsor, CT 06074\\nShip to\\nSatish Kulkarni\\n1006 Sandstone Drive\\nSouth Windsor, CT 06074\\nEstimate details\\nEstimate no.: 721\\nEstimate date: 06/09/2025\\nExpiration date: 07/09/2025\\n#\\nDate\\nProduct or service\\nDescription\\nAmount\\n1.\\nRepair treads and risers on the set of stairs\\nleading to 2nd floor of residence.\\nRemove drywall from under stairs to expose stair\\nframing.\\nRemove and replace any damaged stair framing\\nand/or wedges.\\nAdd wood blocking to stair stringers to support\\ntreads. Wood blocks will be glued and screwed.\\nFasten treads to wood blocking using glue and\\nscrews. Treads will be fastened from below as to\\nnot damage the front surface of the material.\\nInstall cleats for drywall.\\nInstall 1/2in drywall to the underside of stairs\\nwhere drywall was removed.',\n",
       " 'Tape and sand drywall smooth in preparation to\\npaint.\\nInstall crown moulding around perimeter where\\nnew drywall meets walls.\\nPrime and paint ceiling and crown moulding with\\nflat white ceiling paint.\\n2.\\nDryer duct replacement.\\nRemove entire length of existing flexible dryer\\nductwork and hood.\\nInstall new 4in solid aluminum duct.\\nInstall new vent hood (Vent hood will be left white).\\nSeal all seams in duct with aluminum tape.\\nAttach to dryer with 4in hose clamp.\\n3.\\nTotal\\nEstimate includes all materials, labor, and disposal\\nfees to complete the above mentioned work unless\\notherwise noted.\\n$3,800.00\\nTotal\\n$3,800.00\\nExpiry\\ndate\\n07/09/2025\\nAccepted date\\nAccepted by']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_text(text) \n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nembeddings = OpenAIEmbeddings()\\nprompt = ChatPromptTemplate.from_template(template)\\nvectorstore2 = DocArrayInMemorySearch.from_texts(documents, embeddings)\\n\\n\\nchain = (\\n    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\\n    | prompt\\n    | model\\n    | parser\\n)\\nchain.invoke(\"what are the negatives about the book\") '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "\"\"\" Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question} \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "vectorstore2 = DocArrayInMemorySearch.from_texts(documents, embeddings)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"what are the negatives about the book\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "index_name = \"rag-first\"\n",
    "\n",
    "pinecone = PineconeVectorStore.from_texts(\n",
    "    documents, embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The repair description is from Hammer Time Home Improvement and the address is 281 Middle Tpke E, Manchester, CT 06040.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = (\n",
    "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"What company is the repair descption from and what is the address?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
